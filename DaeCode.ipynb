{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members\n",
    "1852529 - Bohlokoa Tilo <br/>\n",
    "1908649 - Tieho Ramphore <br/>\n",
    "1908664 - Thando Peter <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35f58d436427389735ebb75c76f5f772",
     "grade": false,
     "grade_id": "cell-ba1c5e2d317450ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialisation Cell\n",
    "from __future__ import print_function, division\n",
    "from IPython.display import display, HTML, Javascript\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style('darkgrid', {'figure.facecolor': '(0,0,0,0)'}) \n",
    "#'axes.facecolor': '(0,0,0,0)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group: Q Tasks from Mini-project 1 marking\n",
    "#TODO – review methodology <br/>\n",
    "#TODO – Add section contents overview <br/>\n",
    "#TODO – find external source to compare to <br/>\n",
    "#TODO – Check which aspects aren’t checked <br/>\n",
    "#TODO - add ability to answer question <br/>\n",
    "#TODO - Add tidied data excerpt <br/>\n",
    "#TODO - Add sense check commentary <br/>\n",
    "#TODO - Check rendered plots to ensure measures are appropriate <br/>\n",
    "#TODO – Hide long code blocks <br/>\n",
    "#TODO – standardise numbering and font, analyse data more <br/>\n",
    "#TODO – state all assumptions clearly and reference figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "#from sklearn.utils import resample\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title (1)<br>\n",
    "\n",
    "Executive Summary \\ Highlights (7):<br>\n",
    "\n",
    "What is the purpose of this notebook? (1)<br>\n",
    "What is being modelled? (2)<br>\n",
    "What are the main results? (1)<br>\n",
    "Limitations (3)<br>\n",
    "\n",
    "# How personal factors influence income levels and the acquisition of wealth in South Africa\n",
    " \n",
    "## Executive Summary \\ Highlights\n",
    "The purpose of the notebook is to analyse census data from [UCT NIDS databse](http://www.nids.uct.ac.za/nids-data/program-library/derived-files) to determine if:\n",
    "\n",
    "    1) The conditions in which people are born in determine their income bracket and ability to generate wealth in adulthood.\n",
    "    2) The relationships people cultivate throughout their lives contribute to their income bracket and ability to generate wealth.\n",
    "    3) A persons level of education determines the income bracket they can achieve and their ability to generate wealth.\n",
    "\n",
    "The data we will use to model the conditions in which people are born are:\n",
    "\n",
    "    1) Year_DOB\n",
    "    2) Gender\n",
    "    3) Population_Group\n",
    "   \n",
    "The data we will use to model the relationships people cultivate throughout their lives are:\n",
    "\n",
    "    1) Married_Cohabitation\n",
    "    2) Years_Married\n",
    "    3) Years_Cohabiting\n",
    "    4) Current_Relationship_Status\n",
    "    5) Given_Birth\n",
    "    6) Birth_Count\n",
    "    7) Biological_Children_Living\n",
    "    \n",
    "The data we will use to model a persons level of education are:\n",
    "\n",
    "    1) Mother_Degrees \n",
    "    2) Mother_Highest_Tertiary \n",
    "    3) Father_Highest_Tertiary \n",
    "    4) Employment_Payment \n",
    "    5) Highest_Grade_Completed \n",
    "    6) Year_Highest_Grade_Completed \n",
    "    7) Age_Highest_Grade_Completed \n",
    "    8) Highest_Grade_Completed_Pass_Type \n",
    "    9) Matric_University_Exemption \n",
    "    10) Math_Highest_Grade_Completed \n",
    "    11) Other_Math_Highest_Grade_Completed \n",
    "    12) Tertiary_Completed \n",
    "    13) Highest_Tertiary_Completed \n",
    "    14) Other_Highest_Tertiary_Completed \n",
    "    15) Year_Tertiary_Completed \n",
    "    16) Repeated_School_Grades \n",
    "    17) Currently_Enrolled_School \n",
    "    18) Other_Currently_Enrolled_School \n",
    "    19) Computer_Literate\n",
    "    20) English_Reading_Level \n",
    "    21) English_Writing_Level\n",
    "  \n",
    "(Brief) Introduction (10):\n",
    "\n",
    "Problem Context and Motivation (3)<br>\n",
    "Describe Questions (4)<br>\n",
    "Overview of Methodology (2)<br>\n",
    "Section Contents Overview (1)<br>\n",
    "\n",
    "## Introduction\n",
    "**Problem Context and Motivation**: \n",
    "\n",
    "    South Africa is known to be one of the most unequal societies in the world, with the World Bank reporting that 20% of people in South Africa control almost 70% of the resources. In this book, we aim to discover if this inequality is true and if it is, whether education, relationships and birth conditions contribute to it. Our motivation for this study is to find out if it is in the peoples' power to break the chains of poverty and what the best way to go about this is.<br>\n",
    "\n",
    "**Description of the questions asked**:<br>\n",
    "\n",
    "    Question 1: Do the conditions in which people are born in determine their income bracket and ability to generate wealth in adulthood?\n",
    "        There are factors that occur by chance at birth that dictate the life of every person. The factors we explore in this book are race, gender and the year in which a person is born. We aim to find if there are conditions more favorable than others with regards to monetary success in life.\n",
    "        \n",
    "    Question 2: Do the relationships people cultivate throughout their lives contribute to their income bracket and ability to generate wealth?\n",
    "        People have various relationships throughout their lives that last for varying periods. They can remain alone, get married, cohabitate with another and have children. We believe that these relations influence their flow of money and their ability to acquire it. We aim to find out how these relations affect monetary gain and if there are conditions more favorable than others.\n",
    "    \n",
    "    Question 3: Does a persons level of education determines the income bracket they can achieve and their ability to generate wealth?\n",
    "        Through the course of one's life, a person may choose or be forced by circumstance to finish or drop out of grade school, to apply to tertiary or join the workforce, or to pursue a higher degree. These different levels of education have their own advantages and disadvantages. We aim to describe the extent of these advantages with regards to monetary gain. \n",
    "\n",
    "**Methodology**:<br>\n",
    "\n",
    "    1) Remove entries from the dataset that are not complete and are illogical.\n",
    "    2) Clean the data and enforce a standard for data entry.\n",
    "    4) Extract and join rows, columns and tables relevant to each question.\n",
    "    5) Draw exploratory graphs that should help shed light on the data and therefore aid in the answering of the questions.\n",
    "    6) Write an analysis of the findings and formulate a conclusive answer to each question\n",
    "    7) Comment on the accuracy of the data in answering the questions and if any improvements can be made.\n",
    "\n",
    "**Section Contents Overview**:<br>\n",
    "\n",
    "    The following will be a description of the original datasets, the changes perfromed on these datasets, and initial visualisations on data correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       Household_Identifier Sample_Origin  Month_DOB Year_DOB  Gender  \\\n0                    500000   2017 sample      March   1980.0    Male   \n1                    500001   2008 sample    October   1993.0    Male   \n2                    500002   2008 sample  September   1979.0  Female   \n3                    500002   2008 sample     August   1972.0    Male   \n4                    500003   2008 sample   December   1967.0    Male   \n...                     ...           ...        ...      ...     ...   \n30105                513781   2008 sample   December   1985.0    Male   \n30106                513782   2008 sample        NaN      NaN     NaN   \n30107                513782   2008 sample        NaN      NaN     NaN   \n30108                513782   2008 sample        NaN      NaN     NaN   \n30109                513783   2008 sample   December   1985.0  Female   \n\n      Population_Group Married_Cohabitation Years_Married Years_Cohabiting  \\\n0             Coloured     Formally married           5.0              NaN   \n1              African                  NaN           NaN              NaN   \n2              African     Formally married          13.0              NaN   \n3              African     Formally married          15.0              NaN   \n4              African                  NaN           NaN              NaN   \n...                ...                  ...           ...              ...   \n30105          African                  NaN           NaN              NaN   \n30106          Unknown                  NaN           NaN              NaN   \n30107          Unknown                  NaN           NaN              NaN   \n30108          Unknown                  NaN           NaN              NaN   \n30109          African     Formally married           6.0              NaN   \n\n      Current_Relationship_Status  ... Pension_Annuity_Category Shares  \\\n0                             NaN  ...                      NaN     No   \n1                             NaN  ...                      NaN     No   \n2                             NaN  ...                      NaN     No   \n3                             NaN  ...                      NaN     No   \n4                             NaN  ...                      NaN     No   \n...                           ...  ...                      ...    ...   \n30105                         NaN  ...                      NaN     No   \n30106                         NaN  ...                      NaN    NaN   \n30107                         NaN  ...                      NaN    NaN   \n30108                         NaN  ...                      NaN    NaN   \n30109                         NaN  ...                      NaN     No   \n\n      Shares_Amount Shares_Category Bank_Account Bank_Account_Balance  \\\n0               NaN             NaN          Yes            Dont know   \n1               NaN             NaN          Yes                  0.0   \n2               NaN             NaN          Yes               4000.0   \n3               NaN             NaN          Yes              10000.0   \n4               NaN             NaN           No                  NaN   \n...             ...             ...          ...                  ...   \n30105           NaN             NaN           No                  NaN   \n30106           NaN             NaN          NaN                  NaN   \n30107           NaN             NaN          NaN                  NaN   \n30108           NaN             NaN          NaN                  NaN   \n30109           NaN             NaN          Yes                  0.0   \n\n      Bank_Account_Category w5_a_dtacc_cat Possessions_Net_Value  \\\n0                   Refused            NaN   Something left over   \n1                       NaN            NaN            Don't know   \n2                       NaN            NaN   Something left over   \n3                       NaN            NaN   Something left over   \n4                       NaN            NaN               Refused   \n...                     ...            ...                   ...   \n30105                   NaN            NaN   Something left over   \n30106                   NaN            NaN                   NaN   \n30107                   NaN            NaN                   NaN   \n30108                   NaN            NaN                   NaN   \n30109                   NaN            NaN               In debt   \n\n      Possessions_Net_Value_Balance  \n0                          150000.0  \n1                               NaN  \n2                         Dont know  \n3                         Dont know  \n4                               NaN  \n...                             ...  \n30105                        1000.0  \n30106                           NaN  \n30107                           NaN  \n30108                           NaN  \n30109                           NaN  \n\n[30110 rows x 166 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Household_Identifier</th>\n      <th>Sample_Origin</th>\n      <th>Month_DOB</th>\n      <th>Year_DOB</th>\n      <th>Gender</th>\n      <th>Population_Group</th>\n      <th>Married_Cohabitation</th>\n      <th>Years_Married</th>\n      <th>Years_Cohabiting</th>\n      <th>Current_Relationship_Status</th>\n      <th>...</th>\n      <th>Pension_Annuity_Category</th>\n      <th>Shares</th>\n      <th>Shares_Amount</th>\n      <th>Shares_Category</th>\n      <th>Bank_Account</th>\n      <th>Bank_Account_Balance</th>\n      <th>Bank_Account_Category</th>\n      <th>w5_a_dtacc_cat</th>\n      <th>Possessions_Net_Value</th>\n      <th>Possessions_Net_Value_Balance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>500000</td>\n      <td>2017 sample</td>\n      <td>March</td>\n      <td>1980.0</td>\n      <td>Male</td>\n      <td>Coloured</td>\n      <td>Formally married</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>Dont know</td>\n      <td>Refused</td>\n      <td>NaN</td>\n      <td>Something left over</td>\n      <td>150000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500001</td>\n      <td>2008 sample</td>\n      <td>October</td>\n      <td>1993.0</td>\n      <td>Male</td>\n      <td>African</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Don't know</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>500002</td>\n      <td>2008 sample</td>\n      <td>September</td>\n      <td>1979.0</td>\n      <td>Female</td>\n      <td>African</td>\n      <td>Formally married</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>4000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Something left over</td>\n      <td>Dont know</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500002</td>\n      <td>2008 sample</td>\n      <td>August</td>\n      <td>1972.0</td>\n      <td>Male</td>\n      <td>African</td>\n      <td>Formally married</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>10000.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Something left over</td>\n      <td>Dont know</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>500003</td>\n      <td>2008 sample</td>\n      <td>December</td>\n      <td>1967.0</td>\n      <td>Male</td>\n      <td>African</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Refused</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30105</th>\n      <td>513781</td>\n      <td>2008 sample</td>\n      <td>December</td>\n      <td>1985.0</td>\n      <td>Male</td>\n      <td>African</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Something left over</td>\n      <td>1000.0</td>\n    </tr>\n    <tr>\n      <th>30106</th>\n      <td>513782</td>\n      <td>2008 sample</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30107</th>\n      <td>513782</td>\n      <td>2008 sample</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30108</th>\n      <td>513782</td>\n      <td>2008 sample</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30109</th>\n      <td>513783</td>\n      <td>2008 sample</td>\n      <td>December</td>\n      <td>1985.0</td>\n      <td>Female</td>\n      <td>African</td>\n      <td>Formally married</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>In debt</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>30110 rows × 166 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# @hidden_cell\n",
    "# importing data infto dataframe 'df'\n",
    "df = pd.read_stata('DAE-Data/adult_dataset.dta')\n",
    "\n",
    "#selecting specific columns from \"df\"\n",
    "df_filtered = df[\n",
    "    ['w5_hhid','w5_a_sample','w5_a_dob_m','w5_a_dob_y','w5_a_gen','w5_a_popgrp','w5_a_mar','w5_a_mary_m','w5_a_mary_l','w5_a_curmarst',\n",
    "     'w5_a_bhbrth','w5_a_bhcnt1con','w5_a_bhlive','w5_a_mthtertyn','w5_a_mthtert','w5_a_fthtert_o','w5_a_em1','w5_a_em1strty','w5_a_em1inc','w5_a_em1pay',\n",
    "     'w5_a_em1inc_cat','w5_a_em1hrs','w5_a_em1prf','w5_a_em1prf_a','w5_a_em1prflm','w5_a_em1prflm_a','w5_a_em1bon','w5_a_em1bon_a','w5_a_em1bonlm','w5_a_em1bonlm_a',\n",
    "     'w5_a_em1pcrt','w5_a_em1pcrt_a','w5_a_em1pcrtlm','w5_a_em1pcrtlm_a','w5_a_em2','w5_a_em2inc','w5_a_em2pay','w5_a_em2inc_cat','w5_a_ems','w5_a_emssll',\n",
    "     'w5_a_emslft','w5_a_emsincfr_a','w5_a_incgovpen','w5_a_incgovpen_v','w5_a_incdis','w5_a_incdis_v','w5_a_incchld','w5_a_incchld_v','w5_a_incfos','w5_a_incfos_v',\n",
    "     'w5_a_inccare','w5_a_inccare_v','w5_a_incaid','w5_a_incaid_v','w5_a_incwar','w5_a_incwar_v','w5_a_incuif','w5_a_incuif_v','w5_a_incwc','w5_a_incwc_v',\n",
    "     'w5_a_incpfnd','w5_a_incpfnd_v','w5_a_incret','w5_a_incret_v','w5_a_incretp','w5_a_incretp_v','w5_a_incrnt','w5_a_incrnt_v','w5_a_incint','w5_a_incint_v',\n",
    "     'w5_a_incretr','w5_a_incretr_v','w5_a_incinh','w5_a_incinh_v','w5_a_inclob','w5_a_inclob_v','w5_a_incgif','w5_a_incgif_v','w5_a_incloan',\n",
    "     'w5_a_incloan_v','w5_a_incsale','w5_a_incsale_v','w5_a_inco','w5_a_inco_o','w5_a_inco_v','w5_a_cr',\n",
    "     'w5_a_edschgrd','w5_a_edschyr','w5_a_edschage','w5_a_ednsc','w5_a_edexemp','w5_a_edschmth','w5_a_edschmth_o','w5_a_edter',\n",
    "     'w5_a_edterlev','w5_a_edterlev_o','w5_a_edteryr','w5_a_edrep','w5_a_ed17cur',\n",
    "     'w5_a_ed17curlev_o','w5_a_edlitcomp','w5_a_edlitrden','w5_a_edlitwrten','w5_a_fwbrelinc',\n",
    "     'w5_a_fwbstp15','w5_a_fwbstp5yr','w5_a_fwbinc5yr','w5_a_recinh','w5_a_recjob','w5_a_recprof','w5_a_recfin',\n",
    "     'w5_a_reclob','w5_a_recoth','w5_a_ownveh','w5_a_ownveh_v','w5_a_ownmot',\n",
    "     'w5_a_ownmot_v','w5_a_dtbnd','w5_a_dtbnd_b','w5_a_dtbnd_joint','w5_a_ownoth_ind','w5_a_ownowdtot_indshare','w5_a_dtveh','w5_a_dtveh_b',\n",
    "     'w5_a_dtveh_joint','w5_a_dtbnk','w5_a_dtbnk_b','w5_a_dtmic','w5_a_dtmic_b',\n",
    "     'w5_a_dtstubnk','w5_a_dtstubnk_b','w5_a_dtstuo','w5_a_dtstuo_b','w5_a_dtcre','w5_a_dtcre_b','w5_a_dtstr','w5_a_dtstr_b','w5_a_dthp','w5_a_dthp_b',\n",
    "     'w5_a_dtflloan','w5_a_dtflloan_b','w5_a_dtfrloan','w5_a_dtfrloanbal','w5_a_dtmsh','w5_a_dtmsh_b','w5_a_dtemploan','w5_a_dtemploan_b','w5_a_dtunpdtax','w5_a_dtunpdtax_b',\n",
    "     'w5_a_dtserarr','w5_a_dtserarr_b','w5_a_dtoth1','w5_a_dtoth1_o','w5_a_dtoth1_b',\n",
    "     'w5_a_aspen','w5_a_aspen_v','w5_a_aspen_cat','w5_a_asfin','w5_a_asfin_v','w5_a_asfin_cat','w5_a_asacc','w5_a_asacc_v',\n",
    "     'w5_a_asacc_cat','w5_a_dtacc_cat','w5_a_assell','w5_a_assell_v']]\n",
    "\n",
    "#column renaming\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "#dictionary for the new column names: key = old name & value = new name\n",
    "dict={'w5_hhid':'Household_Identifier','w5_a_sample':'Sample_Origin','w5_a_dob_m':'Month_DOB','w5_a_dob_y':'Year_DOB','w5_a_gen':'Gender',\n",
    "      'w5_a_popgrp':'Population_Group','w5_a_mar':'Married_Cohabitation','w5_a_mary_m':'Years_Married','w5_a_mary_l':'Years_Cohabiting',\n",
    "      'w5_a_curmarst':'Current_Relationship_Status','w5_a_bhbrth':'Given_Birth','w5_a_bhcnt1con':'Birth_Count','w5_a_bhlive':'Biological_Children_Living',\n",
    "      'w5_a_mthtertyn':'Mother_Degrees','w5_a_mthtert':'Mother_Highest_Tertiary','w5_a_fthtert_o':'Father_Highest_Tertiary','w5_a_em1':'Employment_Payment',\n",
    "      'w5_a_em1strty':'Primary_Occupation','w5_a_em1inc':'Primary_Gross_Income_Month','w5_a_em1pay':'Primary_Net_Income_Month','w5_a_em1inc_cat':'Main_Job_Income_Category',\n",
    "      'w5_a_em1hrs':'Work_Week_Hours','w5_a_em1prf':'Rec_Share_Profit_Year','w5_a_em1prf_a':'Share_Profit_Year','w5_a_em1prflm':'Rec_Share_Profit_Month',\n",
    "      'w5_a_em1prflm_a':'Share_Profit_Month','w5_a_em1bon':'Rec_Bonus_Year','w5_a_em1bon_a':'Other_Bonus_Year','w5_a_em1bonlm':'Rec_Bonus_Month',\n",
    "      'w5_a_em1bonlm_a':'Other_Bonus_Month','w5_a_em1pcrt':'Rec_Extra_Income_Year','w5_a_em1pcrt_a':'Extra_Income_Year','w5_a_em1pcrtlm':'Rec_Extra_Income_Month',\n",
    "      'w5_a_em1pcrtlm_a':'Extra_Income_Month','w5_a_em2':'Have_Secondary_Occupation','w5_a_em2inc':'Secondary_Gross_Income','w5_a_em2pay':'Secondary_Net_Income',\n",
    "      'w5_a_em2inc_cat':'Secondary_Income_Category','w5_a_ems':'Is_Self_Employed','w5_a_emssll':'Net_After_Liabilities','w5_a_emslft':'Amount_Left_Over',\n",
    "      'w5_a_emsincfr_a':'Month_Take_Home_Salary','w5_a_incgovpen':'Pension','w5_a_incgovpen_v':'Pension_Amount','w5_a_incdis':'Disability_Grant',\n",
    "      'w5_a_incdis_v':'Disability_Grant_Amount','w5_a_incchld':'Child_Support','w5_a_incchld_v':'Child_Support_Amount','w5_a_incfos':'Foster_Care_Grant',\n",
    "      'w5_a_incfos_v':'Foster_Care_Grant_Amount','w5_a_inccare':'Dependency_Grant','w5_a_inccare_v':'Dependency_Grant_Amount','w5_a_incaid':'Grant_In_Aid',\n",
    "      'w5_a_incaid_v':'Grant_In_Aid_Amount','w5_a_incwar':'War_Veterans_Pension','w5_a_incwar_v':'War_Veterans_Pension_Amount','w5_a_incuif':'UIF',\n",
    "      'w5_a_incuif_v':'UIF_Amount','w5_a_incwc':'Workers_Compensation','w5_a_incwc_v':'Workers_Compensation_Amount','w5_a_incpfnd':'Provident_Fund',\n",
    "      'w5_a_incpfnd_v':'Provident_Fund_Amount','w5_a_incret':'Private_Retirement_Annuity','w5_a_incret_v':'Private_Retirement_Annuity_Amount',\n",
    "      'w5_a_incretp':'Retirement_Package','w5_a_incretp_v':'Retirement_Package_Amount','w5_a_incrnt':'Rental_Income','w5_a_incrnt_v':'Rental_Income_Amount',\n",
    "      'w5_a_incint':'Interest_Earnings','w5_a_incint_v':'Interest_Earnings_Amount','w5_a_incretr':'Retrenchment_Package','w5_a_incretr_v':'Retrenchment_Package_Amount',\n",
    "      'w5_a_incinh':'Inheritances','w5_a_incinh_v':'Inheritances_Amount','w5_a_inclob':'Lobola','w5_a_inclob_v':'Lobola_Amount','w5_a_incgif':'Gifts',\n",
    "      'w5_a_incgif_v':'Gifts_Amount','w5_a_incloan':'Loan_Repayments','w5_a_incloan_v':'Loan_Repayments_Amount','w5_a_incsale':'Sale_Household_Goods',\n",
    "      'w5_a_incsale_v':'Sale_Household_Goods_Amount','w5_a_inco':'Other_Income','w5_a_inco_o':'Other_Income_Recipient','w5_a_inco_v':'Other_Income_Value',\n",
    "      'w5_a_cr':'Non_Household_Residents_Contributions','w5_a_edschgrd':'Highest_Grade_Completed','w5_a_edschyr':'Year_Highest_Grade_Completed',\n",
    "      'w5_a_edschage':'Age_Highest_Grade_Completed','w5_a_ednsc':'Highest_Grade_Completed_Pass_Type','w5_a_edexemp':'Matric_University_Exemption',\n",
    "      'w5_a_edschmth':'Math_Highest_Grade_Completed','w5_a_edschmth_o':'Other_Math_Highest_Grade_Completed','w5_a_edter':'Tertiary_Completed',\n",
    "      'w5_a_edterlev':'Highest_Tertiary_Completed','w5_a_edterlev_o':'Other_Highest_Tertiary_Completed','w5_a_edteryr':'Year_Tertiary_Completed',\n",
    "      'w5_a_edrep':'Repeated_School_Grades','w5_a_ed17cur':'Currently_Enrolled_School','w5_a_ed17curlev_o':'Other_Currently_Enrolled_School',\n",
    "      'w5_a_edlitcomp':'Computer_Literate','w5_a_edlitrden':'English_Reading_Level','w5_a_edlitwrten':'English_Writing_Level','w5_a_fwbrelinc':'Household_Income_Classification',\n",
    "      'w5_a_fwbstp15':'Household_Income_Step_15_Years','w5_a_fwbstp5yr':'Household_Income_Step_In_5_Years','w5_a_fwbinc5yr':'Household_Expected_Income_In_5_Years',\n",
    "      'w5_a_recinh':'Income_Inheritance','w5_a_recjob':'Income_Job_Payout','w5_a_recprof':'Income_Property_Sale','w5_a_recfin':'Income_Financial_Product',\n",
    "      'w5_a_reclob':'Income_Lobola','w5_a_recoth':'Income_Other_Payout','w5_a_ownveh':'Vehicle_Owner','w5_a_ownveh_v':'Resale_Vehicle','w5_a_ownmot':'Motorcycle_Owner',\n",
    "      'w5_a_ownmot_v':'Resale_Motorcycle','w5_a_dtbnd':'Has_Home_Loan','w5_a_dtbnd_b':'Home_Loan_Balance','w5_a_dtbnd_joint':'Home_Loan_Joint_Or_Sole',\n",
    "      'w5_a_ownoth_ind':'Other_Property','w5_a_ownowdtot_indshare':'Other_Property_Balance','w5_a_dtveh':'Vehicle_Payment','w5_a_dtveh_b':'Vehicle_Payment_Balance',\n",
    "      'w5_a_dtveh_joint':'Vehicle_Payment_Joint_Or_Sole','w5_a_dtbnk':'Bank_Personal_Loan','w5_a_dtbnk_b':'Bank_Personal_Loan_Balance',\n",
    "      'w5_a_dtmic':'Micro_Lender_Loan','w5_a_dtmic_b':'Micro_Lender_Loan_Balance','w5_a_dtstubnk':'Bank_Study_Loan','w5_a_dtstubnk_b':'Bank_Study_Loan_Balance',\n",
    "      'w5_a_dtstuo':'Other_Study_Loan','w5_a_dtstuo_b':'Other_Study_Loan_Balance','w5_a_dtcre':'Credit_Card','w5_a_dtcre_b':'Credit_Card_Balance',\n",
    "      'w5_a_dtstr':'Store_Card','w5_a_dtstr_b':'Store_Card_Balance','w5_a_dthp':'Hire_Purchase_Agreement','w5_a_dthp_b':'Hire_Purchase_Agreement_Balance',\n",
    "      'w5_a_dtflloan':'Family_Member_Loan','w5_a_dtflloan_b':'Family_Member_Loan_Balance','w5_a_dtfrloan':'Friend_Loan','w5_a_dtfrloanbal':'Friend_Loan_Balance',\n",
    "      'w5_a_dtmsh':'Mashonisa_Loan','w5_a_dtmsh_b':'Mashonisa_Loan_Balance','w5_a_dtemploan':'Employer_Loan','w5_a_dtemploan_b':'Employer_Loan_Balance',\n",
    "      'w5_a_dtunpdtax':'Unpaid_Tax','w5_a_dtunpdtax_b':'Unpaid_Tax_Balance','w5_a_dtserarr':'Monthly_Arrears','w5_a_dtserarr_b':'Monthly_Arrears_Balance',\n",
    "      'w5_a_dtoth1':'Other_Debts','w5_a_dtoth1_o':'Other_Other_Debts','w5_a_dtoth1_b':'Other_Debts_Balance','w5_a_aspen':'Pension_Annuity',\n",
    "      'w5_a_aspen_v':'Pension_Annuity_Amount','w5_a_aspen_cat':'Pension_Annuity_Category','w5_a_asfin':'Shares','w5_a_asfin_v':'Shares_Amount',\n",
    "      'w5_a_asfin_cat':'Shares_Category','w5_a_asacc':'Bank_Account','w5_a_asacc_v':'Bank_Account_Balance','w5_a_asacc_cat':'Bank_Account_Category',\n",
    "      'w5_a_assell':'Possessions_Net_Value','w5_a_assell_v':'Possessions_Net_Value_Balance'}\n",
    "df_filtered.rename(columns = dict,inplace = True)\n",
    "\n",
    "df_filtered['Population_Group'] = df_filtered['Population_Group'].cat.add_categories('Unknown')\n",
    "df_filtered['Population_Group'].fillna('Unknown', inplace = True)\n",
    "\n",
    "display(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description (20):\n",
    "\n",
    "Origin (1)<br> \n",
    "Contents (Who, What, Where) (3)<br> \n",
    "Date Collected (When) (1)<br> \n",
    "Collection Method (How) (2)<br> \n",
    "Dataset Size (rows and columns) (1)<br> \n",
    "Date Downloaded (1)<br> \n",
    "Validations (3)<br> \n",
    "Aspects of Data Quality (see Class Notes) (5)<br> \n",
    "Ability to Answer Question (3)<br> \n",
    "\n",
    "## Data Description\n",
    "\n",
    "The National Income Dynamics Research (NIDS) is South Africa's first national longitudinal study and it served as the main dataset for our project. In 2008 NIDS had its first “Wave” of data collection, which resulted in the collection of a nationally representative sample of close to 7,300 households. The Waves that followed try to conduct interviews on the same households whenever possible. NIDS collects data on a wide range of human resource factors, labour force backgrounds, and demographic characteristics using a mix of household and individual level questionnaires.<br>\n",
    "\n",
    "For this project, we used the dataset from the 5th and latest Wave which took place between February 2017 and December 2017. We only considered the adult dataset as it contains data on the education, employment status, wages and possessions, among other pertinent variables, of the adults in a household.\n",
    "The data was downloaded from [UCT NIDS databse](https://www.datafirst.uct.ac.za/dataportal/index.php/catalog/712/datafile/F2/?offset=100&limit=100) on the 22nd of March 2021 by Rutendo Jambwa. Thando and Bohlokoa cleaned the data by extracting the variables the group deemed relevant to our research and changing their names to improve readability. The resulting dataset had 166 columns and 30 110 entries.<br>\n",
    "\n",
    "Thando further broke down the data into separate subsets, each focusing on specific aspects of the data (e.g. education, income sources, debt, etc..). After which, the individual subsets were further wrangled.<br>\n",
    "\n",
    "To ensure data consistency, column values and data types were modified where necessary such that each column conforms to a single data type. An entry was removed if it had missing values across all columns. In most cases, where possible, missing values were either filled in using some methods or replaced with standard indicators of missing data (i.e. 9999, 00, etc..).<br>\n",
    "\n",
    "**Ability to Answer Questions**:\n",
    "\n",
    "     The dataset has descriptive data that is sufficient in the visualising, calculating and answering of the questions posed above. There are no factors, important to the result of each question, that are not contained and described in detail in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above the data set has 30 110 entries each with at most 166 filled columns. \n",
    "### Quality Analysis\n",
    "\n",
    "After having analysed the whole dataset it can be stated that the data is of good quality. Specific details are highlighted and discussed below.\n",
    "Off of the first set of entries it can be seen that all the entries follow a standard that was prioritised during data collection. This also means that the values are consistent and realistic. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the above the information each column has a set data type that is adhered to throughout the dataset, this means the data present follows a set of decided categories, is a value, or is null. Given the above it can be seen that most columns have null values, this is due to the nature of questioning, there are many factors that a participant may not be part of which are then left null. Included in the dataframe are sample entries which contain null values, given that they have unique house_identifier codes they can be cross-referenced to exisitng entries and be removed if they don't match other entries in the dataframe.\n",
    "\n",
    "Given the size of the dataset and number of present variables per entry we feel that the above dataframe is more than adequate to answer the questions we have regarding income/wealth levels and how they may relate to a series of determining factors. The dataset contains information from the same households over many years which will be instrumental in understanding both income over the course of the decade and wealth generation for the households in the dataset, understanding factors such as the rise/stagnation of education levels and income levels, as well as rising family numbers contrasted with rising debt or a lack of asset accumulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "Sense checks after cleaning (raw vs cleaned) (2)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Details Dataframe\n",
    "\n",
    "The pertinent information captured in the Personal Details dataframe is as follows:\n",
    "\n",
    "#### Household_Identifier\n",
    "\n",
    "1 - 500000 to 513783<br>\n",
    "\n",
    "#### Month_DOB\n",
    "Date of birth (month)\n",
    "\n",
    "1 - January<br>\n",
    "2 - February<br>\n",
    "3 - March<br>\n",
    "4 - April<br>\n",
    "5 - May<br>\n",
    "6 - June<br>\n",
    "7 - July<br>\n",
    "8 - August<br>\n",
    "9 - September<br>\n",
    "10 - October<br>\n",
    "11 - November<br>\n",
    "12 - December<br>\n",
    "13 - Refused<br>\n",
    "14 - Don't know<br>\n",
    "\n",
    "#### Year_DOB\n",
    "Date of birth (year)\n",
    "\n",
    "1 - 1907 to 2003<br>\n",
    "\n",
    "#### Gender\n",
    "Gender\n",
    "\n",
    "1 - Male<br>\n",
    "2 - Female<br>\n",
    "\n",
    "#### Population_Group\n",
    "Population group\n",
    "\n",
    "1 - Coloured<br>\n",
    "2 - African<br>\n",
    "3 - White<br>\n",
    "4 - Asian/Indian<br>\n",
    "5 - Other (specify)<br>\n",
    "6 - Missing<br>\n",
    "\n",
    "#### Married_Cohabitation\n",
    "Formally married or living with a partner\n",
    "\n",
    "1 -     Formally married<br>\n",
    "2 -                   No<br>\n",
    "3 -      Living together<br>\n",
    "\n",
    "#### Years_Married\n",
    "No. of years married to this partner\n",
    "\n",
    "1 - 0.0 to 64.0<br>\n",
    "\n",
    "#### Years_Cohabiting\n",
    "No. of years living with this partner\n",
    "\n",
    "1 - 0.0 to 60.0<br>\n",
    "\n",
    "#### Current_Relationship_Status\n",
    "Currently married, widowed, divorced or separated?\n",
    "\n",
    "1 -                     Single<br>\n",
    "2 -              Widow/Widower<br>\n",
    "3 -      Divorced or separated<br>\n",
    "4 -                    Married<br>\n",
    "\n",
    "#### Given_Birth\n",
    "Ever given birth?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Birth_Count\n",
    "How many children have you given birth to in total?\n",
    "\n",
    "1 - 0.0 to 15.0<br>\n",
    "\n",
    "#### Biological_Children_Living\n",
    "Have biological children living with you?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Mother_Degrees\n",
    "Mother completed diplomas, certificates or degrees?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Mother_Highest_Tertiary\n",
    "Highest level of tertiary education that mother successfully completed\n",
    "\n",
    "1 -                                              NaN<br>\n",
    "2 -           Certificate requiring Grade 12/Std. 10<br>\n",
    "3 -       Certificate not requiring Grade 12/Std. 10<br>\n",
    "4 -           Diploma not requiring Grade 12/Std. 10<br>\n",
    "5 -               Diploma requiring Grade 12/Std. 10<br>\n",
    "6 -                                       Don't know<br>\n",
    "7 -               Higher Degree (Masters, Doctorate)<br>\n",
    "8 -                                 Bachelors Degree<br>\n",
    "9 -                                       N5 (NATED)<br>\n",
    "10 -                                N1 (NATED)/NTC 1<br>\n",
    "11 -                                  Honours Degree<br>\n",
    "12 -                    Bachelors Degree and diploma<br>\n",
    "13 -                                      N6 (NATED)<br>\n",
    "14 -                                         Missing<br>\n",
    "15 -                                 Other (specify)<br>\n",
    "16 -       National Certificate Vocational 4 (NCV 4)<br>\n",
    "17 -       National Certificate Vocational 2 (NCV 2)<br>\n",
    "18 -                                N3 (NATED)/NTC 3<br>\n",
    "\n",
    "#### Father_Highest_Tertiary\n",
    "Highest level of tertiary education father successfully complete\n",
    "\n",
    "1 -          Certificate Of Pumbling<br>\n",
    "2 -                 Tecnical Diploma<br>\n",
    "3 -              Pastors Certificate<br>\n",
    "4 -      Deploma In Higher Education<br>\n",
    "5 -                               -3<br>\n",
    "6 -                   Mining Enering<br>\n",
    "7 -                           Digree<br>\n",
    "8 -                          Teology<br>\n",
    "9 -           Mechanical Engineering<br>\n",
    "10 -                        Building<br>\n",
    "11 -              Diploma In Nursing<br>\n",
    "\n",
    "#### Employment_Payment\n",
    "Are you currently being paid a regular wage/salary; part time/full time?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Highest_Grade_Completed\n",
    "Highest school grade completed\n",
    "\n",
    "1 -                                         Grade 12<br>\n",
    "2 -                                         Grade 10<br>\n",
    "3 -                                         Grade 11<br>\n",
    "4 -                                     No schooling<br>\n",
    "5 -                                          Grade 5<br>\n",
    "6 -                                          Grade 2<br>\n",
    "7 -                                          Grade 7<br>\n",
    "8 -                                          Grade 8<br>\n",
    "9 -                                          Grade 9<br>\n",
    "10 -                                         Grade 4<br>\n",
    "11 -                                         Grade 6<br>\n",
    "12 -                                         Grade 3<br>\n",
    "13 -                                         Grade 1<br>\n",
    "14 -       National Certificate Vocational 3 (NCV 3)<br>\n",
    "15 -                                 Other (specify)<br>\n",
    "16 -                                N3 (NATED)/NTC 3<br>\n",
    "17 -       National Certificate Vocational 4 (NCV 4)<br>\n",
    "18 -                                      Don't know<br>\n",
    "19 -                                         Missing<br>\n",
    "20 -                                N1 (NATED)/NTC 1<br>\n",
    "21 -       National Certificate Vocational 2 (NCV 2)<br>\n",
    "22 -                                         Grade R<br>\n",
    "23 -                                             NaN<br>\n",
    "24 -                                N2 (NATED)/NTC 2<br>\n",
    "25 -                                         Refused<br>\n",
    "\n",
    "#### Year_Highest_Grade_Completed\n",
    "Year in which respondent completed highest grade\n",
    "\n",
    "1 - 0.0 to 2017.0<br>\n",
    "\n",
    "#### Age_Highest_Grade_Completed\n",
    "Age at which respondent completed highest grade\n",
    "\n",
    "1 - 0.0 to 71.0<br>\n",
    "\n",
    "#### Highest_Grade_Completed_Pass_Type\n",
    "Did you pass NSC with a bachelors pass, a diploma pass, or a NSC pass?\n",
    "\n",
    "1 -                                NaN<br>\n",
    "2 -       Passed with a Bachelors pass<br>\n",
    "3 -             Passed with a NSC pass<br>\n",
    "4 -         Passed with a Diploma pass<br>\n",
    "5 -                            Refused<br>\n",
    "6 -                         Don't know<br>\n",
    "7 -                            Missing<br>\n",
    "\n",
    "#### Matric_University_Exemption\n",
    "Did you pass matric with or without a university exemption?\n",
    "\n",
    "1 -          Passed with a university exemption<br>\n",
    "2 -                                         NaN<br>\n",
    "3 -                                  Don't know<br>\n",
    "4 -       Passed without a university exemption<br>\n",
    "5 -                                     Refused<br>\n",
    "\n",
    "#### Math_Highest_Grade_Completed\n",
    "Highest school grade in mathematics completed\n",
    "\n",
    "1 -                                        Grade 12<br>\n",
    "2 -                                         Grade 7<br>\n",
    "3 -                                        Grade 10<br>\n",
    "4 -                                        Grade 11<br>\n",
    "5 -                                             NaN<br>\n",
    "6 -                                         Grade 5<br>\n",
    "7 -                                         Grade 2<br>\n",
    "8 -                                         Grade 8<br>\n",
    "9 -                                         Grade 9<br>\n",
    "10 -                                             25<br>\n",
    "11 -                                     Don't know<br>\n",
    "12 -                                        Grade 6<br>\n",
    "13 -                                        Grade 1<br>\n",
    "14 -                                        Grade 3<br>\n",
    "15 -                                        Grade 4<br>\n",
    "16 -                                        Refused<br>\n",
    "17 -                                Other (specify)<br>\n",
    "18 -                                        Grade R<br>\n",
    "19 -      National Certificate Vocational 2 (NCV 2)<br>\n",
    "20 -                                             32<br>\n",
    "21 -      National Certificate Vocational 4 (NCV 4)<br>\n",
    "22 -                                             31<br>\n",
    "23 -                                        Missing<br>\n",
    "24 -                                             30<br>\n",
    "\n",
    "#### Other_Math_Highest_Grade_Completed\n",
    "Other: Highest school grade in mathematics completed\n",
    "\n",
    "1 -              No<br>\n",
    "2 -        Grade 12<br>\n",
    "3 -        Grade 10<br>\n",
    "4 -        Grade 11<br>\n",
    "\n",
    "#### Tertiary_Completed\n",
    "Respondent has successfully completed some form of tertiary studies?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Highest_Tertiary_Completed\n",
    "Highest level of tertiary education completed\n",
    "\n",
    "1 -                                    Honours Degree<br>\n",
    "2 -                                              None<br>\n",
    "3 -        Certificate not requiring Grade 12/Std. 10<br>\n",
    "4 -                Diploma requiring Grade 12/Std. 10<br>\n",
    "5 -            Certificate requiring Grade 12/Std. 10<br>\n",
    "6 -                Higher Degree (Masters, Doctorate)<br>\n",
    "7 -            Diploma not requiring Grade 12/Std. 10<br>\n",
    "8 -                                        N6 (NATED)<br>\n",
    "9 -                                  Bachelors Degree<br>\n",
    "10 -                                  Other (specify)<br>\n",
    "11 -                                       N5 (NATED)<br>\n",
    "12 -                     Bachelors Degree and diploma<br>\n",
    "13 -        National Certificate Vocational 4 (NCV 4)<br>\n",
    "14 -                                 N3 (NATED)/NTC 3<br>\n",
    "15 -                                 N2 (NATED)/NTC 2<br>\n",
    "16 -                                       N4 (NATED)<br>\n",
    "17 -                                 N1 (NATED)/NTC 1<br>\n",
    "18 -        National Certificate Vocational 3 (NCV 3)<br>\n",
    "19 -        National Certificate Vocational 2 (NCV 2)<br>\n",
    "\n",
    "#### Other_Highest_Tertiary_Completed\n",
    "Other: Highest level of tertiary education completed\n",
    "\n",
    "1 - There are 78 different ansers<br>\n",
    "\n",
    "#### Year_Tertiary_Completed\n",
    "Year in which respondent successfully completed tertiary studies\n",
    "\n",
    "1 - 1940.0 to 2017.0<br>\n",
    "\n",
    "#### Repeated_School_Grades\n",
    "The respondent repeated school grades?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Currently_Enrolled_School\n",
    "Respondent currently enrolled in school or classes?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Computer_Literate\n",
    "Respondent is computer literate?\n",
    "\n",
    "1 -    Yes highly literate<br>\n",
    "2 -          Yes basic use<br>\n",
    "3 -                     No<br>\n",
    "\n",
    "#### English_Reading_Level\n",
    "Respondent's reading level in English\n",
    "\n",
    "1 -      Not well<br>\n",
    "2 -          Fair<br>\n",
    "3 -     Very well<br>\n",
    "4 -    Not at all<br>\n",
    "\n",
    "#### English_Writing_Level\n",
    "Respondent's writing level in English\n",
    "\n",
    "1 -      Not well<br>\n",
    "2 -          Fair<br>\n",
    "3 -     Very well<br>\n",
    "4 -    Not at all<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Object with dtype category cannot perform the numpy op subtract",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8928ed89f7bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mPersonal_Details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age_Highest_Grade_Completed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mPersonal_Details\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPersonal_Details\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Age_Highest_Grade_Completed'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Missing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.0\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'Not applicable'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Refused'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dont know'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mAge_Highest_Grade_Completed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPersonal_Details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year_Highest_Grade_Completed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mPersonal_Details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year_DOB'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mAge_Highest_Grade_Completed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPersonal_Details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age_Highest_Grade_Completed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__sub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rsub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   4993\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4994\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4995\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4997\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_extension_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimedelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# Timedelta is included because numexpr will fail on it, see GH#31457\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[1;31m# for all other cases, raise for now (similarly as what happens in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;31m# Series.__array_prepare__)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   1291\u001b[0m             \u001b[1;34mf\"Object with dtype {self.dtype} cannot perform \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m             \u001b[1;34mf\"the numpy op {ufunc.__name__}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object with dtype category cannot perform the numpy op subtract"
     ]
    }
   ],
   "source": [
    "df_filtered = df_filtered.dropna(subset=['Year_DOB', 'Gender'])\n",
    "Personal_Details = df_filtered[['Household_Identifier','Month_DOB','Year_DOB','Gender','Population_Group','Married_Cohabitation','Years_Married','Years_Cohabiting','Current_Relationship_Status',\n",
    "              'Given_Birth','Birth_Count','Biological_Children_Living','Mother_Degrees','Mother_Highest_Tertiary','Father_Highest_Tertiary','Employment_Payment',\n",
    "              'Highest_Grade_Completed','Year_Highest_Grade_Completed','Age_Highest_Grade_Completed','Highest_Grade_Completed_Pass_Type','Matric_University_Exemption','Math_Highest_Grade_Completed',\n",
    "                'Other_Math_Highest_Grade_Completed','Tertiary_Completed','Highest_Tertiary_Completed','Other_Highest_Tertiary_Completed','Year_Tertiary_Completed',\n",
    "              'Repeated_School_Grades','Currently_Enrolled_School','Other_Currently_Enrolled_School','Computer_Literate','English_Reading_Level','English_Writing_Level']]\n",
    "#\n",
    "# Drop columns with no data\n",
    "Personal_Details = Personal_Details.dropna(subset=['Year_DOB', 'Gender'])\n",
    "\n",
    "Personal_Details = Personal_Details.replace({'Year_DOB': {'Don\\'t know': 1950.0}})\n",
    "Personal_Details['Year_DOB'] = Personal_Details['Year_DOB'].astype(str).astype(float)\n",
    "\n",
    "# Group non-cohabitation categories\n",
    "Personal_Details['Married_Cohabitation'] = Personal_Details['Married_Cohabitation'].cat.add_categories('No')\n",
    "Personal_Details['Married_Cohabitation'].fillna('No', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Married_Cohabitation': {'Not living together': 'No', 'Don\\'t know': 'No', 'Missing': 'No', 'Refused': 'No'}})\n",
    "Personal_Details['Married_Cohabitation'] = Personal_Details['Married_Cohabitation'].astype('category')\n",
    "\n",
    "Personal_Details['Years_Married'] = Personal_Details['Years_Married'].cat.add_categories(0.0)\n",
    "Personal_Details['Years_Married'].fillna(0.0, inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Years_Married': {'Dont know': 0.0, 'Missing': 0.0}})\n",
    "\n",
    "Personal_Details['Years_Cohabiting'] = Personal_Details['Years_Cohabiting'].cat.add_categories(0.0)\n",
    "Personal_Details['Years_Cohabiting'].fillna(0.0, inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Years_Cohabiting': {'Dont know': 0.0, 'Refused': 0.0, 'Missing': 0.0}})\n",
    "\n",
    "Personal_Details['Current_Relationship_Status'] = Personal_Details['Current_Relationship_Status'].cat.add_categories('Single')\n",
    "Personal_Details['Current_Relationship_Status'].fillna('Single', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Current_Relationship_Status': {'Don\\'t know': 'Single', 'Refused': 'Single'}})\n",
    "Personal_Details['Current_Relationship_Status'] = Personal_Details['Current_Relationship_Status'].astype('category')\n",
    "Personal_Details['Father_Highest_Tertiary'] = Personal_Details['Father_Highest_Tertiary'].astype('category')\n",
    "\n",
    "Personal_Details['Given_Birth'].fillna('No', inplace = True)\n",
    "\n",
    "Personal_Details['Birth_Count'] = Personal_Details['Birth_Count'].cat.add_categories(0.0)\n",
    "Personal_Details['Birth_Count'].fillna(0.0, inplace = True)\n",
    "\n",
    "Personal_Details['Mother_Degrees'].fillna('No', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Mother_Degrees': {'Don\\'t know': 'No', 'Refused': 'No', 'Missing':'No'}})\n",
    "Personal_Details['Mother_Degrees'] = Personal_Details['Mother_Degrees'].astype('category')\n",
    "\n",
    "Personal_Details['Year_Highest_Grade_Completed'] = Personal_Details['Year_Highest_Grade_Completed'].cat.add_categories(0.0)\n",
    "Personal_Details['Year_Highest_Grade_Completed'].fillna(0.0, inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Year_Highest_Grade_Completed': {'Missing':0.0 ,'Not Applicable': 0.0, 'Refused': 0.0, 'Don\\'t know': 0.0}})\n",
    "\n",
    "# 'Age_Highest_Grade_Completed' if we subtract 'Year_DOB' from 'Year_Highest_Grade_Completed'\n",
    "Personal_Details['Age_Highest_Grade_Completed'] = Personal_Details['Age_Highest_Grade_Completed'].cat.add_categories(0.0)\n",
    "Personal_Details['Age_Highest_Grade_Completed'].fillna(0.0, inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Age_Highest_Grade_Completed': {'Missing':0.0 ,'Not applicable': 0.0, 'Refused': 0.0, 'Dont know': 0.0}})\n",
    "Age_Highest_Grade_Completed = Personal_Details['Year_Highest_Grade_Completed'] - Personal_Details['Year_DOB']\n",
    "for i, v in Age_Highest_Grade_Completed.items():\n",
    "    if(Personal_Details['Age_Highest_Grade_Completed'][i] == 0 and v>0):\n",
    "        Personal_Details['Age_Highest_Grade_Completed'][i] = v\n",
    "        \n",
    "#Replacing the values of the highest grade achieved column with the terms currently used\n",
    "new_edu_vals = {'Grade R/0':'Grade R','Grade 1/Sub A/Class 1':'Grade 1','Grade 2/Sub B/Class 2':'Grade 2','Grade 3/Std. 1':'Grade 3','Grade 4/Std. 2':'Grade 4','Grade 5/Std. 3':'Grade 5','Grade 6/Std. 4':'Grade 6','Grade 8/Std. 6/Form 1':'Grade 8','Grade 12/Std. 10/Form 5/Matric/Senior Certificate':'Grade 12','Grade 10/Std. 8/Form 3':'Grade 10','Grade 11/Std. 9/Form 4':'Grade 11','Grade 9/Std. 7/Form 2':'Grade 9','Grade 7/Std. 5':'Grade 7'}\n",
    "Personal_Details = Personal_Details.replace({'Math_Highest_Grade_Completed': new_edu_vals}) # The data still has random numbers and vocational certificates\n",
    "Personal_Details = Personal_Details.replace({'Highest_Grade_Completed': new_edu_vals})\n",
    "Personal_Details['Highest_Grade_Completed'] = Personal_Details['Highest_Grade_Completed'].astype('category')\n",
    "Personal_Details['Math_Highest_Grade_Completed'] = Personal_Details['Math_Highest_Grade_Completed'].astype('category')\n",
    "    \n",
    "Personal_Details = Personal_Details.replace({'Other_Math_Highest_Grade_Completed': {'':'No','N6 Deploma':'No','N6 Diploma':'No','Respondent Say All Levels':'Grade 12','Didn\\'T Do Mathematics At School. It Used To Be Called Dipalo Back Then.':'No','According To The Respondent She Never Did Mathematics At School':'No','The Respondent Said She Didnt Do Any Mathematics Course But She Did An Arethmatic':'No','Respondent Never Had Mathemetics On School But Had Accountncy Instead':'No','The Respondent Say\\'S She Did Not Do Mathematics At School':'No','The Respondent Say He Never Did Mathematics At School':'No','No Mathematics In Dissabled School.':'No','Never Did Mathematics At School.':'No','-3':'No','Respondent Never Did Mathematics At School':'No','The Respondent Never Did Matahematics At School.':'No','The Respondent Says She Never Did Mathematics At School.':'No','The Respondent Says He Never Did Mathematics At School':'No','She Was In Disabled School':'No','The Respondent Does Not Remember':'No','Respondent Did Not Do Mathematics At School.':'No','Not At All':'No','He Confirmed That He Nver Studied Mathematics':'No','No Grades':'No','Thr Respondent Never Did Mathematics At Work':'No','No Grades Respondent Attenden A Special School':'No','Never':'No','Maths Leteracy':'No','Never Did Mathematics At School. He\\'S Doing Maths Literary.':'No','The Respondend Says She Never Studied Mathematics At School':'No','A-Level':'Grade 12','The Respondent Ddnt Do Maths At School':'No','Ptc':'No','He Did Not Do Mathematics':'No','Didnt Finish School Left After Standard 5':'No','None':'No','He Didn\\'T Study Maths':'No','Cop Is What The Respondent Studied From Over Seas He Used The American Syllabus Not From South Africa':'No','There Was No Mathematics As A Subject Back When She Was Still In School.':'No','She Did Mathematics Up Until Her A Level(Grade 12)':'No','The Was No Mathematics At The Time He Was Schooling':'No','Sester(Grade 6 In Mozambican Education System)':'No','Nover Did Mathematics':'No','Never Did Maths At All':'No','Never Had Any Maths As Subject In School':'No','Didnt Pass With Maths':'No','She Was Attending Special School':'No','Form 6':'Grade 12','No Grades Its A Special .School':'No','Not Doing Grades':'No','Respondent Never Did Mathematics At School.':'No','She Never Did Mathematics At School':'No','I Didnt I Left School Early':'No','He Never Did Mathematics':'No','Never Studied Maths':'No','Did Not Have Mathematics That Time':'No','Form C':'Grade 10','Jc':'No','The Respondent Say She Never Study Mathematics At School':'No','A Level(Grade 12)':'Grade 12','The Respondent Says She Never Did Matric':'Grade 11','She Did Mathematics Till She Completed School':'Grade 12','He Did To It Untill He Finish School.':'Grade 12','According To The Respondent He Never Did Mathematics At School':'No','According To The Respondent She Never Did Maths At Schoool':'No','He Is Attending Trade School':'No','She Didn\\'T Study Mathematics':'No','The Respondent Says She Ddnt Do Mathematics':'No','Respondent Says She Did Arithmetic And Not Mathematics.':'No','The Respondent Says She Ddnt Do Mathematics At School':'No','She Did Not Do Mathematics At School.':'No','Did Not Do Maths':'No','They Just Teach Them How To Their Self Only':'No','Never Did Maths':'No','The Was No At The Time He Was Schooling':'No','Never Did Mathematics At School. She\\'S Doing Maths Literacy.':'No','Respondent Didn\\'T Do Mathtematics At School.':'No','He Was Attending A Special School, Did Not Have Grade.':'No','Never Did Mathematics At School. Was Doing Maths Literacy.':'No','She Says She Never Did Mathematics At School':'No','The Respondent Says He Has Never Done Mathematics At School.':'No','The Respondent Sais She Never Studied Mathematics':'No','Didn\\'T Do Mathematics At School':'No','Did Not Do Mathematics':'No','Did Not Do Mathematics At All':'No','Respondent Never Id Pure Mathemathics At School':'No','Did Not Do Maths At High School':'No','Never Did Mathematics':'No'}})\n",
    "Personal_Details['Other_Math_Highest_Grade_Completed'] = Personal_Details['Other_Math_Highest_Grade_Completed'].astype('category')\n",
    "\n",
    "Personal_Details['Highest_Tertiary_Completed'] = Personal_Details['Highest_Tertiary_Completed'].cat.add_categories('None')\n",
    "Personal_Details['Highest_Tertiary_Completed'].fillna( 'None', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Highest_Tertiary_Completed': {'Missing':'None' , 'Refused':'None' , 'Don\\'t know':'None' }})\n",
    "Personal_Details['Highest_Tertiary_Completed'] = Personal_Details['Highest_Tertiary_Completed'].astype('category')\n",
    "\n",
    "Personal_Details['Tertiary_Completed'].fillna( 'No', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Tertiary_Completed': {'Missing':'No' , 'Refused':'No' , 'Don\\'t know':'No' }})\n",
    "Personal_Details['Tertiary_Completed'][i] = ('Yes' for i, v in Personal_Details['Highest_Tertiary_Completed'] if v!='None')\n",
    "Personal_Details['Tertiary_Completed'][30109] = 'No'\n",
    "Personal_Details['Tertiary_Completed'] = Personal_Details['Tertiary_Completed'].astype('category')\n",
    "\n",
    "Personal_Details = Personal_Details.replace({'Year_Tertiary_Completed': {'Missing':None , 'Not Applicable':None , 'Refused':None , 'Don\\'t know':None }})\n",
    "\n",
    "Personal_Details = Personal_Details.replace({'Repeated_School_Grades': {'Missing':None , 'Refused':None , 'Don\\'t know':None }})\n",
    "Personal_Details['Repeated_School_Grades'] = Personal_Details['Repeated_School_Grades'].astype('category')\n",
    "\n",
    "Personal_Details['Currently_Enrolled_School'].fillna( 'No', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Currently_Enrolled_School': {'Missing':'No' , 'Refused':'No' , 'Don\\'t know':'No' }})\n",
    "Personal_Details['Currently_Enrolled_School'] = Personal_Details['Currently_Enrolled_School'].astype('category')\n",
    "\n",
    "Personal_Details['Computer_Literate'].fillna( 'No', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'Computer_Literate': {'Missing':'No' , 'Refused':'No' , 'Don\\'t know':'No' }})\n",
    "Personal_Details['Computer_Literate'] = Personal_Details['Computer_Literate'].astype('category')\n",
    "\n",
    "Personal_Details['English_Reading_Level'].fillna( 'Not well', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'English_Reading_Level': {'Missing':'Not well' , 'Refused':'Not well' , 'Don\\'t know':'Not well' }})\n",
    "Personal_Details['English_Reading_Level'] = Personal_Details['English_Reading_Level'].astype('category')\n",
    "\n",
    "Personal_Details['English_Writing_Level'].fillna( 'Not well', inplace = True)\n",
    "Personal_Details = Personal_Details.replace({'English_Writing_Level': {'Missing':'Not well' , 'Refused':'Not well' , 'Don\\'t know':'Not well' }})\n",
    "Personal_Details['English_Writing_Level'] = Personal_Details['English_Writing_Level'].astype('category')\n",
    "\n",
    "display(Personal_Details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset Details Dataframe\n",
    "\n",
    "The pertinent information captured in the Asset Details dataframe is as follows:\n",
    "\n",
    "#### Is_Self_Employed\n",
    "Existence of self-employment?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Net_After_Liabilities\n",
    "Net worth of business after liquidation credit, breakeven or debt\n",
    "\n",
    "1 - Breakeven<br>\n",
    "2 - Profit<br>\n",
    "\n",
    "#### Vehicle_Owner\n",
    "Ownership of a motor vehicle(including bakkie or truck)?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Motorcycle_Owner\n",
    "Ownership of a motorcycle/scooter?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Pension_Annuity\n",
    "Has a pension or retirement annuity?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Pension_Annuity_Category\n",
    "Cash value of pension/annuity category, created from brackets\n",
    "\n",
    "1 - R500<br>\n",
    "2 - R501-R4,999<br>\n",
    "3 - R5,000<br>\n",
    "4 - R5,001-R49,999<br>\n",
    "5 - R50,000<br>\n",
    "6 - R50,001-R499,999<br>\n",
    "7 - R500,000<br>\n",
    "8 - R500,001-R999,999<br>\n",
    "9 - R1,000,000<br>\n",
    "10 - R1,000,001-R4,999,999<br>\n",
    "11 - >R5,000,000<br>\n",
    "\n",
    "#### Shares\n",
    "Has unit trusts, stocks or shares?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Shares_Category\n",
    "Cash value of unit trust/stocks/shares category, created from brackets\n",
    "\n",
    "1 - R500<br>\n",
    "2 - R501-R4,999<br>\n",
    "3 - R5,000<br>\n",
    "4 - R5,001-R49,999<br>\n",
    "5 - R50,000<br>\n",
    "6 - R50,001-R499,999<br>\n",
    "7 - R500,000<br>\n",
    "8 - R500,001-R999,999<br>\n",
    "9 - R1,000,000<br>\n",
    "10 - R1,000,001-R4,999,999<br>\n",
    "11 - >R5,000,000<br>\n",
    "\n",
    "#### Bank_Account\n",
    "Has a bank account?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Bank_Account_Category\n",
    "Bank account category, created from brackets\n",
    "\n",
    "1 - >R100,000 in overdraft<br>\n",
    "2 - R50,001-R100,000 in overdraft<br>\n",
    "3 - R5,001-R50,000 in overdraft<br>\n",
    "4 - R501-R5,000 in overdraft<br>\n",
    "5 - R1-R500 in overdraft<br>\n",
    "6 - R500<br>\n",
    "7 - R501-R4,999<br>\n",
    "8 - R5,000<br>\n",
    "9 - R5,001-R49,999<br>\n",
    "10 - R50,000<br>\n",
    "11 - R50,001-R499,999<br>\n",
    "12 - R500,000<br>\n",
    "13 - R500,001-R999,999<br>\n",
    "14 - R1,000,000<br>\n",
    "15 - R1,000,001-R4,999,999<br>\n",
    "16 - >R5,000,000<br>\n",
    "\n",
    "#### Possessions_Net_Value\n",
    "Net value of hh possessions including home (credit/breakeven/debt)\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Asset_Details = df_filtered[['Is_Self_Employed','Net_After_Liabilities','Amount_Left_Over','Vehicle_Owner','Resale_Vehicle','Motorcycle_Owner',\n",
    "                             'Resale_Motorcycle','Pension_Annuity','Pension_Annuity_Amount','Pension_Annuity_Category','Shares','Shares_Amount','Shares_Category',\n",
    "                             'Bank_Account','Bank_Account_Balance','Bank_Account_Category','Possessions_Net_Value','Possessions_Net_Value_Balance']]\n",
    "\n",
    "Asset_Details = Asset_Details.replace({'Is_Self_Employed': {'Missing':'No' , 'Refused':'No' , 'Don\\'t know':'No' }})\n",
    "Asset_Details['Is_Self_Employed'] = Asset_Details['Is_Self_Employed'].astype('category')\n",
    "\n",
    "Asset_Details = Asset_Details.replace({'Amount_Left_Over': {'Not applicable':None , 'Refused':None , 'Dont know':None }})\n",
    "\n",
    "Asset_Details['Net_After_Liabilities'] = Asset_Details['Net_After_Liabilities'].cat.add_categories('Profit')\n",
    "Asset_Details['Net_After_Liabilities'] = Asset_Details['Net_After_Liabilities'].cat.add_categories('Loss')\n",
    "for i, v in Asset_Details['Amount_Left_Over'].items():\n",
    "    if pd.isna(v):\n",
    "        Asset_Details['Is_Self_Employed'][i] = 'No'\n",
    "        Asset_Details['Net_After_Liabilities'][i] = None\n",
    "        Asset_Details['Amount_Left_Over'][i] = 0.0\n",
    "    else:\n",
    "        Asset_Details['Is_Self_Employed'][i] = 'Yes'\n",
    "        if v<0:\n",
    "            Asset_Details['Net_After_Liabilities'][i] = 'Loss'\n",
    "        elif v>0:\n",
    "            Asset_Details['Net_After_Liabilities'][i] = 'Profit'\n",
    "        else:\n",
    "            Asset_Details['Net_After_Liabilities'][i] = 'Breakeven'\n",
    "Asset_Details['Net_After_Liabilities'] = Asset_Details['Net_After_Liabilities'].astype('object').astype('category')\n",
    "\n",
    "def clean_owner_resale( Asset_Details, col1, col2):\n",
    "    Asset_Details[col1] = Asset_Details[col1].astype('object')\n",
    "    Asset_Details = Asset_Details.replace({col2: {'Not applicable':None , 'Refused':None , 'Dont know':None , 'Don\\'t know':None , 'Missing':None }})\n",
    "    for i, v in Asset_Details[col2].items():\n",
    "        if pd.isna(v):\n",
    "            Asset_Details[col1][i] = 'No'\n",
    "            Asset_Details[col2][i] = 0.0\n",
    "        else:\n",
    "            Asset_Details[col1][i] = 'Yes'\n",
    "    Asset_Details[col1] = Asset_Details[col1].astype('category')\n",
    "    Asset_Details[col2] = Asset_Details[col2].astype('float')\n",
    "    return Asset_Details\n",
    "\n",
    "def clean_amount_category(Asset_Details, amount, category):\n",
    "    Asset_Details[category] = Asset_Details[category].astype('object')\n",
    "    for i, v in Asset_Details[amount].items():\n",
    "        if v<-100000:\n",
    "            Asset_Details[category][i] = '>R100,000 in overdraft'\n",
    "        elif v>=-100000 and v<=-50001:\n",
    "            Asset_Details[category][i] = 'R50,001-R100,000 in overdraft'\n",
    "        elif v>=-50000 and v<=-5001:\n",
    "            Asset_Details[category][i] = 'R5,001-R50,000 in overdraft'\n",
    "        elif v>=-5000 and v<=-501:\n",
    "            Asset_Details[category][i] = 'R501-R5,000 in overdraft'\n",
    "        elif v>=-500 and v<0:\n",
    "            Asset_Details[category][i] = 'R1-R500 in overdraft'\n",
    "        elif v<=500 and v>=0:\n",
    "            Asset_Details[category][i] = 'R500'\n",
    "        elif v>=501 and v<=4999:\n",
    "            Asset_Details[category][i] = 'R501-R4,999'\n",
    "        elif v==5000:\n",
    "            Asset_Details[category][i] = 'R5,000'\n",
    "        elif v>=5001 and v<=49999:\n",
    "            Asset_Details[category][i] = 'R5,001-R49,999'\n",
    "        elif v==50000:\n",
    "            Asset_Details[category][i] = 'R50,000'\n",
    "        elif v>=50001 and v<=499999:\n",
    "            Asset_Details[category][i] = 'R50,001-R499,999'\n",
    "        elif v==500000:\n",
    "            Asset_Details[category][i] = 'R500,000'\n",
    "        elif v>=500001 and v<=999999:\n",
    "            Asset_Details[category][i] = 'R500,001-R999,999'\n",
    "        elif v==1000000:\n",
    "            Asset_Details[category][i] = 'R1,000,000'\n",
    "        elif v>=1000001 and v<=4999999:\n",
    "            Asset_Details[category][i] = 'R1,000,001-R4,999,999'\n",
    "        elif v==5000000:\n",
    "            Asset_Details[category][i] = 'R5,000,000'\n",
    "        elif v>5000000:\n",
    "            Asset_Details[category][i] = '>R5,000,000'\n",
    "    Asset_Details[category] = Asset_Details[category].astype('category')\n",
    "    return Asset_Details\n",
    "\n",
    "Asset_Details = clean_owner_resale(Asset_Details, 'Vehicle_Owner', 'Resale_Vehicle')\n",
    "Asset_Details = clean_owner_resale(Asset_Details, 'Motorcycle_Owner', 'Resale_Motorcycle')\n",
    "\n",
    "Asset_Details = clean_owner_resale(Asset_Details, 'Pension_Annuity', 'Pension_Annuity_Amount')\n",
    "Asset_Details = clean_amount_category(Asset_Details, 'Pension_Annuity_Amount', 'Pension_Annuity_Category')\n",
    "\n",
    "Asset_Details = clean_owner_resale(Asset_Details, 'Shares', 'Shares_Amount')\n",
    "Asset_Details = clean_amount_category(Asset_Details, 'Shares_Amount', 'Shares_Category')\n",
    "\n",
    "Asset_Details = clean_owner_resale(Asset_Details, 'Bank_Account', 'Bank_Account_Balance')\n",
    "Asset_Details = clean_amount_category(Asset_Details, 'Bank_Account_Balance', 'Bank_Account_Category')\n",
    "\n",
    "Asset_Details = clean_owner_resale(Asset_Details, 'Possessions_Net_Value', 'Possessions_Net_Value_Balance')\n",
    "\n",
    "display(Asset_Details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Details Dataframe\n",
    "\n",
    "The pertinent information captured in the Income Details dataframe is as follows:\n",
    "\n",
    "#### Employment_Payment\n",
    "Are you currently being paid a regular wage/salary; part time/full time?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Primary_Gross_Income_Month\n",
    "Gross income for primary occupation last month\n",
    "\n",
    "1 - 0.0 to 65 000 000.0<br>\n",
    "\n",
    "#### Primary_Net_Income_Month\n",
    "Net income for primary occupation last month\n",
    "\n",
    "1 - 0.0 to 65 000 000.0<br>\n",
    "\n",
    "#### Main_Job_Income_Category\n",
    "Main job income category, created from brackets\n",
    "\n",
    "1 - R500<br>\n",
    "2 - R501-R4,999<br>\n",
    "3 - R5,000<br>\n",
    "4 - R5,001-R49,999<br>\n",
    "5 - R50,000<br>\n",
    "6 - R50,001-R499,999<br>\n",
    "7 - R500,000<br>\n",
    "8 - R500,001-R999,999<br>\n",
    "9 - R1,000,000<br>\n",
    "10 - R1,000,001-R4,999,999<br>\n",
    "11 - >R5,000,000<br>\n",
    "\n",
    "#### Work_Week_Hours\n",
    "Average work week (hours) at primary occupation\n",
    "\n",
    "1 - 0.0 to 168.0\n",
    "\n",
    "#### Rec_Share_Profit_Year\n",
    "Received share of profit in last 12 months?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Rec_Share_Profit_Month\n",
    "Received share of profit in last month?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Rec_Bonus_Year\n",
    "Received other bonus in the last 12 months?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Rec_Bonus_Month\n",
    "Received other bonus in last month?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Rec_Extra_Income_Year\n",
    "Received extra income on piece rate basis in last 12 months?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Rec_Extra_Income_Month\n",
    "Received extra income on piece rate basis in last month?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Have_Secondary_Occupation\n",
    "Existence of secondary occupation?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Secondary_Income_Category\n",
    "Second job income category, created from brackets\n",
    "\n",
    "1 -                 R500<br>\n",
    "2 -          R501-R4,999<br>\n",
    "3 -       R5,001-R49,999<br>\n",
    "\n",
    "#### Is_Self_Employed\n",
    "Existence of self-employment?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Pension\n",
    "Recipient of state (RSA) pension?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Disability_Grant\n",
    "Recipient of disability grant?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Child_Support\n",
    "Recipient of child support grant?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Foster_Care_Grant\n",
    "Recipient of foster care grant?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Dependency_Grant\n",
    "Recipient of care dependency grant?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Grant_In_Aid\n",
    "Recipient of grant in aid?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### War_Veterans_Pension\n",
    "Recipient of war veterans pension?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### UIF\n",
    "Recipient of (unemployment insurance) UIF?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Workers_Compensation\n",
    "Recipient of worker's compensation?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Provident_Fund\n",
    "Recipient of pension or provident fund?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Private_Retirement_Annuity\n",
    "Recipient of private retirement annuity?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Retirement_Package\n",
    "Recipient of retirement gratuity/package?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Rental_Income\n",
    "Recipient of rental income?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Interest_Earnings\n",
    "Recipient of interest earnings?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Retrenchment_Package\n",
    "Recipient of retrenchment package?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Inheritances\n",
    "Recipient of inheritances?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Lobola\n",
    "Recipient of lobola/bride wealth?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Gifts\n",
    "Recipient of gifts?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Loan_Repayments\n",
    "Recipient of loan repayments?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Sale_Household_Goods\n",
    "Recipient of income from sale of household goods?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Other_Income\n",
    "Recipient of other income?\n",
    "\n",
    "1 - Yes<br>\n",
    "2 - No<br>\n",
    "\n",
    "#### Household_Income_Classification\n",
    "Income classification of household\n",
    "\n",
    "1                   Average income<br>\n",
    "2        Much below average income<br>\n",
    "3             Below average income<br>\n",
    "4             Above average income<br>\n",
    "5        Much above average income<br>\n",
    "6                       Don't know<br>\n",
    "7                          Refused<br>\n",
    "8                          Missing<br>\n",
    "9                              NaN<br>\n",
    "\n",
    "#### Household_Income_Step_15_Years\n",
    "Income step of household when 15 years-old\n",
    "\n",
    "1                  Ladder Rung 2<br>\n",
    "2                     Don't know<br>\n",
    "3        Ladder Rung 1 (Poorest)<br>\n",
    "4                  Ladder Rung 3<br>\n",
    "5                  Ladder Rung 4<br>\n",
    "6        Ladder Rung 6 (Richest)<br>\n",
    "7                  Ladder Rung 5<br>\n",
    "8                        Refused<br>\n",
    "9                        Missing<br>\n",
    "10                           NaN<br>\n",
    "\n",
    "#### Household_Income_Step_In_5_Years\n",
    "Income step of household in 5 years' time\n",
    "\n",
    "1                  Ladder Rung 2<br>\n",
    "2                     Don't know<br>\n",
    "3        Ladder Rung 1 (Poorest)<br>\n",
    "4                  Ladder Rung 3<br>\n",
    "5                  Ladder Rung 4<br>\n",
    "6        Ladder Rung 6 (Richest)<br>\n",
    "7                  Ladder Rung 5<br>\n",
    "8                        Refused<br>\n",
    "9                        Missing<br>\n",
    "10                           NaN<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Income_Details = df_filtered[['Employment_Payment','Primary_Gross_Income_Month','Primary_Net_Income_Month','Main_Job_Income_Category',\n",
    "                              'Work_Week_Hours','Rec_Share_Profit_Year','Share_Profit_Year','Rec_Share_Profit_Month','Share_Profit_Month','Rec_Bonus_Year',\n",
    "                              'Other_Bonus_Year','Rec_Bonus_Month','Other_Bonus_Month','Rec_Extra_Income_Year','Extra_Income_Year','Rec_Extra_Income_Month',\n",
    "                              'Extra_Income_Month','Have_Secondary_Occupation','Secondary_Gross_Income','Secondary_Net_Income','Secondary_Income_Category',\n",
    "                              'Is_Self_Employed','Month_Take_Home_Salary','Pension','Pension_Amount','Disability_Grant','Disability_Grant_Amount','Child_Support',\n",
    "                              'Child_Support_Amount','Foster_Care_Grant','Foster_Care_Grant_Amount','Dependency_Grant','Dependency_Grant_Amount','Grant_In_Aid',\n",
    "                              'Grant_In_Aid_Amount','War_Veterans_Pension','War_Veterans_Pension_Amount','UIF','UIF_Amount','Workers_Compensation',\n",
    "                              'Workers_Compensation_Amount','Provident_Fund','Provident_Fund_Amount','Private_Retirement_Annuity',\n",
    "                              'Private_Retirement_Annuity_Amount','Retirement_Package','Retirement_Package_Amount','Rental_Income','Rental_Income_Amount',\n",
    "                              'Interest_Earnings','Interest_Earnings_Amount','Retrenchment_Package','Retrenchment_Package_Amount','Inheritances',\n",
    "                              'Inheritances_Amount','Lobola','Lobola_Amount','Gifts','Gifts_Amount','Loan_Repayments','Loan_Repayments_Amount',\n",
    "                              'Sale_Household_Goods','Sale_Household_Goods_Amount','Other_Income','Other_Income_Recipient','Other_Income_Value',\n",
    "                              'Household_Income_Classification','Household_Income_Step_15_Years',\n",
    "                              'Household_Income_Step_In_5_Years','Household_Expected_Income_In_5_Years']]\n",
    "\n",
    "Income_Details['Primary_Gross_Income_Month'].fillna(0.0, inplace = True)\n",
    "Income_Details = Income_Details.replace({'Primary_Gross_Income_Month': {'Missing':0.0 ,'Not applicable': 0.0, 'Refused': 0.0, 'Dont know': 0.0}})\n",
    "Income_Details['Primary_Net_Income_Month'].fillna(0.0, inplace = True)\n",
    "Income_Details = Income_Details.replace({'Primary_Net_Income_Month': {'Missing':0.0 ,'Not applicable': 0.0, 'Refused': 0.0, 'Dont know': 0.0}})\n",
    "\n",
    "def clean_payment_existence( Income_Details, col1, col2):\n",
    "    Income_Details[col2] = Income_Details[col2].astype('object')\n",
    "    Income_Details = Income_Details.replace({col2: {'Missing':0.0 ,'Not applicable': 0.0, 'Refused': 0.0, 'Dont know': 0.0}})\n",
    "    Income_Details[col2].fillna(0.0, inplace = True)\n",
    "    for i, v in Income_Details[col2].items():\n",
    "        if v>0:\n",
    "            Income_Details[col1][i] = 'Yes'\n",
    "        else:\n",
    "            Income_Details[col1][i] = 'No'\n",
    "    Income_Details[col1] = Income_Details[col1].astype('object').astype('category')\n",
    "    return Income_Details\n",
    "\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Employment_Payment', 'Primary_Gross_Income_Month')\n",
    "Personal_Details['Employment_Payment'] = Income_Details['Employment_Payment']\n",
    "\n",
    "Income_Details = clean_amount_category(Income_Details, 'Primary_Net_Income_Month', 'Main_Job_Income_Category')\n",
    "\n",
    "Income_Details['Work_Week_Hours'].fillna(0.0, inplace = True)\n",
    "Income_Details = Income_Details.replace({'Work_Week_Hours': {'Missing':0.0 ,'Not applicable': 0.0, 'Refused': 0.0, 'Dont know': 0.0}})\n",
    "\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Rec_Share_Profit_Year', 'Share_Profit_Year')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Rec_Share_Profit_Month', 'Share_Profit_Month')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Rec_Bonus_Year', 'Other_Bonus_Year')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Rec_Bonus_Month', 'Other_Bonus_Month')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Rec_Extra_Income_Year', 'Extra_Income_Year')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Rec_Extra_Income_Month', 'Extra_Income_Month')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Have_Secondary_Occupation', 'Secondary_Gross_Income')\n",
    "Income_Details = clean_payment_existence( Income_Details, 'Have_Secondary_Occupation', 'Secondary_Net_Income')\n",
    "\n",
    "Income_Details = clean_amount_category(Income_Details, 'Secondary_Net_Income', 'Secondary_Income_Category')\n",
    "\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Is_Self_Employed', 'Month_Take_Home_Salary')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Pension', 'Pension_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Disability_Grant', 'Disability_Grant_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Child_Support', 'Child_Support_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Foster_Care_Grant', 'Foster_Care_Grant_Amount')\n",
    "\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Dependency_Grant', 'Dependency_Grant_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Grant_In_Aid', 'Grant_In_Aid_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'War_Veterans_Pension', 'War_Veterans_Pension_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'UIF', 'UIF_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Workers_Compensation', 'Workers_Compensation_Amount')\n",
    "\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Workers_Compensation', 'Workers_Compensation_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Provident_Fund', 'Provident_Fund_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Private_Retirement_Annuity', 'Private_Retirement_Annuity_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Retirement_Package', 'Retirement_Package_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Rental_Income', 'Rental_Income_Amount')\n",
    "\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Interest_Earnings', 'Interest_Earnings_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Retrenchment_Package', 'Retrenchment_Package_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Inheritances', 'Inheritances_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Lobola', 'Lobola_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Gifts', 'Gifts_Amount')\n",
    "\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Loan_Repayments', 'Loan_Repayments_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Sale_Household_Goods', 'Sale_Household_Goods_Amount')\n",
    "Income_Details = clean_payment_existence(Income_Details, 'Other_Income', 'Other_Income_Value')\n",
    "\n",
    "Income_Details['Household_Expected_Income_In_5_Years'].fillna(0.0, inplace = True)\n",
    "Income_Details = Income_Details.replace({'Household_Expected_Income_In_5_Years': {'Missing':0.0 ,'Not applicable': 0.0, 'Refused': 0.0, 'Dont know': 0.0}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liability Details Dataframe\n",
    "\n",
    "The pertinent information captured in the Liability Details dataframe is as follows:\n",
    "\n",
    "#### Has_Home_Loan\n",
    "Has a home loan/bond?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Other_Property\n",
    "Do you own any other properties or land? Include any foreign properties.\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Vehicle_Payment\n",
    "Have a vehicle finance (car repayment)?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Bank_Personal_Loan\n",
    "Has a personal loan from a bank?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Micro_Lender_Loan\n",
    "Has a personal loan from a micro-lender?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Bank_Study_Loan\n",
    "Has a study loan with a bank?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Other_Study_Loan\n",
    "Has a study loan with an institution other than a bank?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Credit_Card\n",
    "Has a credit card?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Store_Card\n",
    "Has a store card?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Hire_Purchase_Agreement\n",
    "Has a hire purchase agreement?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Family_Member_Loan\n",
    "Has a loan from a family member?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Friend_Loan\n",
    "Has a loan from friend?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Mashonisa_Loan\n",
    "Has a loan with a mashonisa?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Employer_Loan\n",
    "Has a loan from an employer?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Unpaid_Tax\n",
    "Has unpaid tax, including PAYE, property taxes and VAT?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Monthly_Arrears\n",
    "Has arrears in service and other monthly bills?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "#### Other_Debts\n",
    "Has other debts (specify)?\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Liability_Details = df_filtered[['Has_Home_Loan','Home_Loan_Balance','Other_Property','Other_Property_Balance',\n",
    "                                 'Vehicle_Payment','Vehicle_Payment_Balance','Bank_Personal_Loan','Bank_Personal_Loan_Balance',\n",
    "                                 'Micro_Lender_Loan','Micro_Lender_Loan_Balance','Bank_Study_Loan','Bank_Study_Loan_Balance','Other_Study_Loan','Other_Study_Loan_Balance',\n",
    "                                 'Credit_Card','Credit_Card_Balance','Store_Card','Store_Card_Balance','Hire_Purchase_Agreement','Hire_Purchase_Agreement_Balance',\n",
    "                                 'Family_Member_Loan','Family_Member_Loan_Balance','Friend_Loan','Friend_Loan_Balance','Mashonisa_Loan','Mashonisa_Loan_Balance',\n",
    "                                 'Employer_Loan','Employer_Loan_Balance','Unpaid_Tax','Unpaid_Tax_Balance','Monthly_Arrears','Monthly_Arrears_Balance','Other_Debts',\n",
    "                                 'Other_Debts_Balance']]\n",
    "\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Has_Home_Loan', 'Home_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Other_Debts', 'Other_Debts_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Unpaid_Tax', 'Unpaid_Tax_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Employer_Loan', 'Employer_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Family_Member_Loan', 'Family_Member_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Bank_Study_Loan', 'Bank_Study_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Hire_Purchase_Agreement', 'Hire_Purchase_Agreement_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Other_Study_Loan', 'Other_Study_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Bank_Personal_Loan', 'Bank_Personal_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Vehicle_Payment', 'Vehicle_Payment_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Micro_Lender_Loan', 'Micro_Lender_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Friend_Loan', 'Friend_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Credit_Card', 'Credit_Card_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Mashonisa_Loan', 'Mashonisa_Loan_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Store_Card', 'Store_Card_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Other_Property', 'Other_Property_Balance')\n",
    "Liability_Details = clean_payment_existence(Liability_Details, 'Monthly_Arrears', 'Monthly_Arrears_Balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encode variables\n",
    "\n",
    "Personal_Details = Month_DOB, Gender, Population_Group, Married_Cohabitation, Current_Relationship_Status, Given_Birth, Biological_Children_Living, Mother_Degrees, Mother_Highest_Tertiary, Father_Highest_Tertiary, Highest_Grade_Completed, Highest_Grade_Completed_Pass_Type, Matric_University_Exemption, Math_Highest_Grade_Completed, Other_Math_Highest_Grade_Completed, Tertiary_Completed, Highest_Tertiary_Completed, Other_Highest_Tertiary_Completed,Repeated_School_Grades, Currently_Enrolled_School, Other_Currently_Enrolled_School, Computer_Literate, English_Reading_Level, English_Writing_Level\n",
    "\n",
    "Asset_Details = Is_Self_Employed, Net_After_Liabilities, Vehicle_Owner, Motorcycle_Owner, Pension_Annuity, Pension_Annuity_Category, Shares, Shares_Category, Bank_Account, Bank_Account_Category, Possessions_Net_Value\n",
    "\n",
    "Income_Details = Employment_Payment, Main_Job_Income_Category, Rec_Share_Profit_Year, Rec_Share_Profit_Month, Rec_Bonus_Year, Rec_Bonus_Month, Rec_Extra_Income_Year, Rec_Extra_Income_Month, Have_Secondary_Occupation, War_Veterans_Pension, Retirement_Package, UIF, Is_Self_Employed, Foster_Care_Grant, Disability_Grant, Household_Income_Classification, Household_Income_Step_15_Years, Retrenchment_Package, Other_Income_Recipient, Sale_Household_Goods, Gifts, Household_Income_Step_In_5_Years, Other_Income, Interest_Earnings, Loan_Repayments, Lobola, Rental_Income, Inheritances, Provident_Fund, Dependency_Grant, Private_Retirement_Annuity, Workers_Compensation, Grant_In_Aid, Child_Support, Secondary_Income_Category, Pension\n",
    "\n",
    "Liability_Details = Has_Home_Loan, Other_Property, Vehicle_Payment, Bank_Personal_Loan, Micro_Lender_Loan, Bank_Study_Loan, Other_Study_Loan, Credit_Card, Store_Card, Hire_Purchase_Agreement, Family_Member_Loan, Friend_Loan, Mashonisa_Loan, Employer_Loan, Unpaid_Tax, Monthly_Arrears, Other_Debts\n",
    "\n",
    "The columns above are categorical and need to be transformed into indicator variables using one-hot encoding.\n",
    "\n",
    "\n",
    "Many of the variables collected via survey have string responses which separate all entries into categories, these values however cannot be used in numerical functions. Therefore in order to use these variables they need to be turned into indicator variables. One hot encoding will be used to ensure no information is lost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cols = ['Month_DOB', 'Gender', 'Population_Group', 'Married_Cohabitation', 'Current_Relationship_Status', 'Given_Birth', 'Biological_Children_Living', 'Mother_Degrees', 'Mother_Highest_Tertiary', 'Father_Highest_Tertiary', 'Highest_Grade_Completed', 'Highest_Grade_Completed_Pass_Type', 'Matric_University_Exemption', 'Math_Highest_Grade_Completed', 'Other_Math_Highest_Grade_Completed', 'Tertiary_Completed', 'Highest_Tertiary_Completed', 'Other_Highest_Tertiary_Completed','Repeated_School_Grades', 'Currently_Enrolled_School', 'Other_Currently_Enrolled_School', 'Computer_Literate', 'English_Reading_Level', 'English_Writing_Level']\n",
    "Personal_Details_Dummies = pd.get_dummies(Personal_Details, columns = Cols, drop_first = False)\n",
    "Personal_Details = pd.concat([Personal_Details,Personal_Details_Dummies],axis=1)\n",
    "\n",
    "Cols = ['Is_Self_Employed', 'Net_After_Liabilities', 'Vehicle_Owner', 'Motorcycle_Owner', 'Pension_Annuity', 'Pension_Annuity_Category', 'Shares', 'Shares_Category', 'Bank_Account', 'Bank_Account_Category', 'Possessions_Net_Value']\n",
    "Asset_Details_Dummies = pd.get_dummies(Asset_Details,columns=Cols,drop_first=False)\n",
    "Asset_Details = pd.concat([Asset_Details,Asset_Details_Dummies],axis=1)\n",
    "\n",
    "Cols = ['Employment_Payment', 'Main_Job_Income_Category', 'Rec_Share_Profit_Year', 'Rec_Share_Profit_Month', 'Rec_Bonus_Year', 'Rec_Bonus_Month', 'Rec_Extra_Income_Year', 'Rec_Extra_Income_Month', 'Have_Secondary_Occupation', 'War_Veterans_Pension', 'Retirement_Package', 'UIF', 'Is_Self_Employed', 'Foster_Care_Grant', 'Disability_Grant', 'Household_Income_Classification', 'Household_Income_Step_15_Years', 'Retrenchment_Package', 'Other_Income_Recipient', 'Sale_Household_Goods', 'Gifts', 'Household_Income_Step_In_5_Years', 'Other_Income', 'Interest_Earnings', 'Loan_Repayments', 'Lobola', 'Rental_Income', 'Inheritances', 'Provident_Fund', 'Dependency_Grant', 'Private_Retirement_Annuity', 'Workers_Compensation', 'Grant_In_Aid', 'Child_Support', 'Secondary_Income_Category', 'Pension']\n",
    "Income_Details_Dummies = pd.get_dummies(Income_Details,columns=Cols,drop_first=False)\n",
    "Income_Details = pd.concat([Income_Details,Income_Details_Dummies],axis=1)\n",
    "\n",
    "Cols = ['Has_Home_Loan', 'Other_Property', 'Vehicle_Payment', 'Bank_Personal_Loan', 'Micro_Lender_Loan', 'Bank_Study_Loan', 'Other_Study_Loan', 'Credit_Card', 'Store_Card', 'Hire_Purchase_Agreement', 'Family_Member_Loan', 'Friend_Loan', 'Mashonisa_Loan', 'Employer_Loan', 'Unpaid_Tax', 'Monthly_Arrears', 'Other_Debts']\n",
    "Liability_Details_Dummies = pd.get_dummies(Liability_Details,columns=Cols,drop_first=False)\n",
    "Liability_Details = pd.concat([Liability_Details,Liability_Details_Dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore the relationships between the personal data and how that impacts the Income, Assests and Liabilities of each residence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the values of the highest grade achieved column with the terms currently used\n",
    "new_edu_vals = {'Grade R/0':'Grade R','Grade 1/Sub A/Class 1':'Grade 1','Grade 2/Sub B/Class 2':'Grade 2','Grade 3/Std. 1':'Grade 3','Grade 4/Std. 2':'Grade 4','Grade 5/Std. 3':'Grade 5','Grade 6/Std. 4':'Grade 6','Grade 8/Std. 6/Form 1':'Grade 8','Grade 12/Std. 10/Form 5/Matric/Senior Certificate':'Grade 12','Grade 10/Std. 8/Form 3':'Grade 10','Grade 11/Std. 9/Form 4':'Grade 11','Grade 9/Std. 7/Form 2':'Grade 9','Grade 7/Std. 5':'Grade 7'}\n",
    "df_filtered = df_filtered.replace({'Highest_Grade_Completed': new_edu_vals})\n",
    "edu_lvl = df_filtered['Highest_Grade_Completed'].dropna() #dropping nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the highest grade achieved data\n",
    "fig = plt.figure(figsize=(9,7))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.hist(edu_lvl, width = 0.45, bins = 24)\n",
    "\n",
    "ax.set_ylabel('No. of Respondents')\n",
    "ax.set_xlabel('Grade')\n",
    "ax.set_title('Highest Grade Accomplished by Respondent')\n",
    "plt.xticks(rotation = 90)\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison between highest grade completed and monthly take home salary\n",
    "\n",
    "piv_data = df_filtered.loc[:,['Month_Take_Home_Salary','Highest_Grade_Completed']]\n",
    "piv_data.dropna()\n",
    "piv_tbl = pd.pivot_table(piv_data, index = ['Month_Take_Home_Salary'] , columns =['Highest_Grade_Completed'], aggfunc = len, fill_value = 0)\n",
    "piv_tbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison between tertiary education and monthly take home salary\n",
    "piv_data2 = df_filtered.loc[:,['Month_Take_Home_Salary','Tertiary_Completed']]\n",
    "piv_data2.dropna()\n",
    "piv_tbl2 = pd.pivot_table(piv_data2, index = ['Month_Take_Home_Salary'] , columns =['Tertiary_Completed'], aggfunc = len,fill_value = 0)\n",
    "piv_tbl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = df_filtered['Population_Group']\n",
    "#Comparison between tertiary education and monthly take home salary\n",
    "piv_data3 = df_filtered.loc[:,['Population_Group','Tertiary_Completed','Highest_Tertiary_Completed']]\n",
    "piv_data3.dropna()\n",
    "piv_tbl3 = pd.pivot_table(piv_data3, index =['Tertiary_Completed','Highest_Tertiary_Completed'] , columns =['Population_Group'], aggfunc = len,fill_value = 0)\n",
    "piv_tbl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#piv_tbl3 plot results\n",
    "plt.figure(figsize=(10,8))\n",
    "piv_tbl3.plot(kind = \"bar\", figsize = (10,8), stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.35\n",
    "plt.hist(race, width = width)\n",
    "plt.title('Histogram of Population Groups')\n",
    "plt.xlabel('Population Group')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(50)\n",
    "df_filtered.info(verbose= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marriage, in community of wealth\n",
    "\n",
    "Examining how different stages of a relationship (living separately, cohabiting, married) affect wealth, Are married couples more wealthy than cohabiting couples? Are people who are single wealthier than divorced people,widows,widowers or separated people? Are people who have been married longer wealthier and does number of children affect wealth?\n",
    "The data we will use to model the relationships in this section:\n",
    "\n",
    "    1) Married_Cohabitation\n",
    "    2) Years_Married\n",
    "    3) Years_Cohabiting\n",
    "    4) Current_Relationship_Status\n",
    "    5) Given_Birth\n",
    "    6) Birth_Count\n",
    "    7) Biological_Children_Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below we will assume an entry with NAN for current relationship status is single.\n",
    "statSalary_piv = df_filtered.loc[:,['Month_Take_Home_Salary','Current_Relationship_Status']]\n",
    "statSalary_piv['Current_Relationship_Status'] = statSalary_piv['Current_Relationship_Status'].cat.add_categories('Single')\n",
    "statSalary_piv['Current_Relationship_Status'].fillna('Single',inplace=True)\n",
    "statSalary_piv.dropna(inplace= True)\n",
    "statSalary_piv_tbl = pd.pivot_table(statSalary_piv, index = ['Month_Take_Home_Salary'] , columns =['Current_Relationship_Status'], aggfunc = len, fill_value = 0)\n",
    "statSalary_piv_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "statSalary_piv_tbl.plot(kind = \"bar\", figsize = (15,8), stacked = True)"
   ]
  },
  {
   "source": [
    "#### Monthly Salary Analysis\n",
    "\n",
    "From the above graph it can be seen that single people outearn all other groups in higher monthly take-home salaries. The second highest earning group would be divorced groups, appearing heavily in the higher monthly salaries values and very briefly in the lower classes. The married group can be seen mainly in the average earning group, this suggest that marriage does not lead to higher monthly take home salaries but also prevents the lowest possible findings. Single people also outnumber all other interviewed groups thereby skewing the insights gained from <reference graph here>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comarison between marriage status and monthly salary\n",
    "statSalary_piv = df_filtered.loc[:,['Month_Take_Home_Salary','Married_Cohabitation']]\n",
    "statSalary_piv.dropna(inplace=True)\n",
    "statSalary_piv_tbl = pd.pivot_table(statSalary_piv, index = ['Month_Take_Home_Salary'] , columns =['Married_Cohabitation'], aggfunc = len, fill_value = 0)\n",
    "statSalary_piv_tbl"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comarison between marriage status and possession net value balance\n",
    "statPoss_piv = df_filtered.loc[:,['Possessions_Net_Value_Balance','Current_Relationship_Status']]\n",
    "statPoss_piv.dropna(inplace=True)\n",
    "statPoss_piv.head(20)\n",
    "statPoss_piv_tbl = pd.pivot_table(statPoss_piv, index =['Possessions_Net_Value_Balance'] , columns =['Current_Relationship_Status'], aggfunc = len, fill_value = 0)\n",
    "statPoss_piv_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "statPoss_piv_tbl.plot(kind = \"bar\", figsize = (20,12), stacked = True)"
   ]
  },
  {
   "source": [
    "#### Possession Analysis\n",
    "\n",
    "Given that most participants did not know their net possession valuation a fully sketched conclusion cannot be drawn, but from what data could be assembled it is clear that divorced participants hold the most net possessions. In all value amounts the highest number is that of divorced people. From this and the previous exploratory plot a trend is being formed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years cohabiting vs years married with possessions net\n",
    "# Assumptions are that any couple with NaN for possessions net balance has a neglible net possession value thus it is set to 0\n",
    "MvC_piv = df_filtered.loc[:,['Possessions_Net_Value_Balance','Years_Cohabiting','Years_Married']]\n",
    "MvC_piv.dropna(how = \"all\",inplace=True)\n",
    "# for i in MvC_piv:\n",
    "#     if (i['Years_Cohabiting'] == 'NaN') and (i['Years_Married'] == 'NaN'):\n",
    "#         #delete it i guess\n",
    "# MvC_piv.fillna(0,inplace=True)\n",
    "MvC_piv.head(20)\n",
    "# MvC_piv_tbl = pd.pivot_table(MvC_piv, index =['Possessions_Net_Value_Balance'] , columns =['Years_Cohabiting','Years_Married'], aggfunc = len, fill_value = 0)\n",
    "# MvC_piv_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affect of children on wealth\n",
    "MvC_piv = df_filtered.loc[:,['Possessions_Net_Value_Balance','Years_Cohabiting','Years_Married']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd048e3f7a102c5d06de3195a78a7296e612992126078ee80939e66cc55eb7c37df",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "48e3f7a102c5d06de3195a78a7296e612992126078ee80939e66cc55eb7c37df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}